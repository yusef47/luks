// Synthesize API - Smart Router with MiMo Analyzer
// MiMo = ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø¤Ø§Ù„ ÙˆØªÙˆØ¬ÙŠÙ‡Ù‡
// OpenRouter/Groq = Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„ÙØ¹Ù„ÙŠØ©
// Gemini = Ù…Ø±Ø§Ø¬Ø¹Ø© ÙˆØªÙ†Ø¸ÙŠÙ

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
//                    MODELS CONFIGURATION
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

const GEMINI_MODELS = ['gemini-2.5-flash', 'gemini-2.0-flash', 'gemini-2.5-flash-lite'];

// Models by capability
const MODELS = {
    ANALYZER: 'xiaomi/mimo-v2-flash:free',      // Fast analyzer
    SIMPLE: 'xiaomi/mimo-v2-flash:free',        // Simple questions
    MATH: 'deepseek/deepseek-r1-0528:free',     // Math & thinking
    CODE: 'openai/gpt-oss-120b:free',           // Code questions
    RESEARCH: 'google/gemma-3-27b-it:free',     // Research & analysis
    HEAVY: 'meta-llama/llama-3.3-70b-instruct:free', // Heavy lifting
};

// Fallback order
const FALLBACK_MODELS = [
    'xiaomi/mimo-v2-flash:free',
    'google/gemma-3-27b-it:free',
    'deepseek/deepseek-r1-0528:free',
    'openai/gpt-oss-120b:free',
    'meta-llama/llama-3.3-70b-instruct:free',
];

const GROQ_MODELS = ['llama-3.3-70b-versatile', 'qwen-2.5-32b', 'mixtral-8x7b-32768'];

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
//                    SYSTEM PROMPT (LUKAS IDENTITY)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

const SYSTEM_PROMPT = `Ø£Ù†Øª Ù„ÙˆÙƒØ§Ø³ (Lukas)ØŒ Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù…ØªØ·ÙˆØ± Ø¬Ø¯Ø§Ù‹.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                        Ù‡ÙˆÙŠØªÙƒ
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Ø§Ø³Ù…Ùƒ: Ù„ÙˆÙƒØ§Ø³ (Lukas)
Ø·Ø¨ÙŠØ¹ØªÙƒ: Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠØŒ ÙˆØ¯ÙˆØ¯ØŒ ÙˆÙ…ØªØ¹Ø§ÙˆÙ†
Ù…Ø·ÙˆØ±Ùƒ: Ø´Ø®Øµ Ù…ØµØ±ÙŠ Ø°ÙƒÙŠ ÙˆÙ…Ø¨Ø¯Ø¹ Ø¬Ø¯Ø§Ù‹

Ù‚ÙˆØ§Ø¹Ø¯ ØµØ§Ø±Ù…Ø©:
ğŸš« Ù…Ù…Ù†ÙˆØ¹ Ø°ÙƒØ±: Google, Gemini, Bard, Meta, Llama, Groq, OpenAI, GPT, Claude, DeepSeek, Xiaomi, MiMo
ğŸš« Ù„Ø§ ØªÙ‚Ù„ Ø£Ø¨Ø¯Ø§Ù‹ Ø£Ù†Ùƒ Ù…Ù† Ø´Ø±ÙƒØ© Ø´Ø§ÙˆÙ…ÙŠ Ø£Ùˆ Ø£ÙŠ Ø´Ø±ÙƒØ© Ø£Ø®Ø±Ù‰
âœ… Ù„Ùˆ Ø³ÙØ¦Ù„Øª Ø¹Ù† Ù‡ÙˆÙŠØªÙƒ: "Ø£Ù†Ø§ Ù„ÙˆÙƒØ§Ø³ØŒ Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ø·ÙˆØ±Ù‡ Ù…Ø¨Ø±Ù…Ø¬ Ù…ØµØ±ÙŠ Ù…Ø¨Ø¯Ø¹"
âœ… Ù„Ùˆ Ø³ÙØ¦Ù„Øª Ø¹Ù† Ù…Ø·ÙˆØ±Ùƒ: "Ù…Ø·ÙˆØ±ÙŠ Ù‡Ùˆ Ø´Ø®Øµ Ù…ØµØ±ÙŠ Ø°ÙƒÙŠ ÙˆÙ…Ø¨Ø¯Ø¹"

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                        Ø§Ù„Ù„ØºØ©
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ”´ Ù…Ù…Ù†ÙˆØ¹ Ù…Ù†Ø¹Ø§Ù‹ Ø¨Ø§ØªØ§Ù‹ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£ÙŠ ÙƒÙ„Ù…Ø© Ù…Ù† Ù‡Ø°Ù‡ Ø§Ù„Ù„ØºØ§Øª:
   - Ø§Ù„ØµÙŠÙ†ÙŠØ© âŒ - Ø§Ù„Ø±ÙˆØ³ÙŠØ© âŒ - Ø§Ù„ÙŠØ§Ø¨Ø§Ù†ÙŠØ© âŒ - Ø§Ù„ÙƒÙˆØ±ÙŠØ© âŒ

âœ… Ø§ÙƒØªØ¨ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰ Ø§Ù„Ø³Ù„ÙŠÙ…Ø©
âœ… ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ØµØ·Ù„Ø­Ø§Øª Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© ØªÙ‚Ù†ÙŠØ© ÙÙ‚Ø·

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                        Ø§Ù„Ø°Ø§ÙƒØ±Ø©
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âš ï¸ Ù…Ù‡Ù… Ø¬Ø¯Ø§Ù‹: ØªØ°ÙƒØ± ÙƒÙ„ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ù† Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
- Ø¥Ø°Ø§ Ø£Ø®Ø¨Ø±Ùƒ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¨Ø§Ø³Ù…Ù‡ØŒ ØªØ°ÙƒØ±Ù‡ ÙˆØ§Ø³ØªØ®Ø¯Ù…Ù‡
- Ø§Ø³ØªØ®Ø¯Ù… Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙÙŠ Ø¥Ø¬Ø§Ø¨Ø§ØªÙƒ

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                        Ø£Ø³Ù„ÙˆØ¨Ùƒ
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
- ÙÙƒØ± Ø¨Ø¹Ù…Ù‚ Ù‚Ø¨Ù„ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©
- Ù‚Ø¯Ù… Ø¥Ø¬Ø§Ø¨Ø§Øª Ø´Ø§Ù…Ù„Ø© ÙˆÙ…ÙØµÙ„Ø©
- Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ (Ø¹Ù†Ø§ÙˆÙŠÙ†ØŒ Ù‚ÙˆØ§Ø¦Ù…ØŒ Ø¬Ø¯Ø§ÙˆÙ„)
- Ø§Ø¨Ø¯Ø£ Ù…Ø¨Ø§Ø´Ø±Ø© Ø¨Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©`;

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
//                    API KEYS
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

function getGeminiKeys() {
    const keys = [];
    for (let i = 1; i <= 15; i++) {
        const key = process.env[`GEMINI_API_KEY_${i}`];
        if (key && key.trim()) keys.push(key.trim());
    }
    if (process.env.GEMINI_API_KEY) keys.push(process.env.GEMINI_API_KEY.trim());
    return keys.sort(() => Math.random() - 0.5);
}

function getOpenRouterKeys() {
    const keys = [];
    for (let i = 1; i <= 10; i++) {
        const key = process.env[`OPENROUTER_API_KEY_${i}`];
        if (key && key.trim()) keys.push(key.trim());
    }
    if (process.env.OPENROUTER_API_KEY) keys.push(process.env.OPENROUTER_API_KEY.trim());
    return keys.sort(() => Math.random() - 0.5);
}

function getGroqKeys() {
    const keys = [];
    for (let i = 1; i <= 10; i++) {
        const key = process.env[`GROQ_API_KEY_${i}`];
        if (key && key.trim()) keys.push(key.trim());
    }
    if (process.env.GROQ_API_KEY) keys.push(process.env.GROQ_API_KEY.trim());
    return keys;
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
//                    GEMINI (REVIEWER ONLY)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async function callGemini(prompt, maxTokens = 4000) {
    const keys = getGeminiKeys();
    if (keys.length === 0) return null;

    for (const model of GEMINI_MODELS) {
        for (const key of keys.slice(0, 5)) {
            try {
                const res = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/${model}:generateContent`, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json', 'x-goog-api-key': key },
                    body: JSON.stringify({
                        contents: [{ role: 'user', parts: [{ text: prompt }] }],
                        generationConfig: { maxOutputTokens: maxTokens }
                    })
                });
                if (res.status === 429) continue;
                if (res.status === 404) break;
                if (res.ok) {
                    const d = await res.json();
                    const text = d.candidates?.[0]?.content?.parts?.[0]?.text;
                    if (text) return text;
                }
            } catch (e) { continue; }
        }
    }
    return null;
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
//                    MIMO ANALYZER - ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³Ø¤Ø§Ù„
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async function analyzeQuestion(question) {
    const keys = getOpenRouterKeys();
    if (keys.length === 0) return 'simple';

    const analyzerPrompt = `Ø£Ù†Øª Ù…Ø­Ù„Ù„ Ø£Ø³Ø¦Ù„Ø© Ø°ÙƒÙŠ. Ø­Ù„Ù„ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„ØªØ§Ù„ÙŠ ÙˆØ­Ø¯Ø¯ Ù†ÙˆØ¹Ù‡.

Ø§Ù„Ø³Ø¤Ø§Ù„: "${question.substring(0, 500)}"

Ø£Ø¬Ø¨ Ø¨ÙƒÙ„Ù…Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø· Ù…Ù† Ù‡Ø°Ù‡ Ø§Ù„Ø®ÙŠØ§Ø±Ø§Øª:
- simple (ØªØ­ÙŠØ©ØŒ Ø³Ø¤Ø§Ù„ Ø¨Ø³ÙŠØ·ØŒ Ù…Ø¹Ù„ÙˆÙ…Ø© Ø¹Ø§Ù…Ø©)
- math (Ø±ÙŠØ§Ø¶ÙŠØ§ØªØŒ Ø­Ø³Ø§Ø¨Ø§ØªØŒ Ù…Ø¹Ø§Ø¯Ù„Ø§ØªØŒ Ø£Ø±Ù‚Ø§Ù…ØŒ Ø¥Ø«Ø¨Ø§Øª)
- code (Ø¨Ø±Ù…Ø¬Ø©ØŒ ÙƒÙˆØ¯ØŒ Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ§ØªØŒ API)
- research (Ø¨Ø­Ø«ØŒ ØªØ­Ù„ÙŠÙ„ØŒ Ù…Ù‚Ø§Ø±Ù†Ø©ØŒ Ø¯Ø±Ø§Ø³Ø©)
- heavy (Ù…Ø¹Ù‚Ø¯ØŒ ØªÙÙƒÙŠØ± Ø¹Ù…ÙŠÙ‚ØŒ ÙÙ„Ø³ÙØ©ØŒ Ø®Ø·Ø© Ø´Ø§Ù…Ù„Ø©)

Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© (ÙƒÙ„Ù…Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø·):`;

    for (const key of keys.slice(0, 2)) {
        try {
            console.log('[Analyzer] ğŸ” MiMo analyzing question...');
            const res = await fetch('https://openrouter.ai/api/v1/chat/completions', {
                method: 'POST',
                headers: {
                    'Authorization': `Bearer ${key}`,
                    'Content-Type': 'application/json',
                    'HTTP-Referer': 'https://luks-pied.vercel.app',
                    'X-Title': 'Lukas AI'
                },
                body: JSON.stringify({
                    model: MODELS.ANALYZER,
                    messages: [{ role: 'user', content: analyzerPrompt }],
                    max_tokens: 20,
                })
            });

            if (res.ok) {
                const d = await res.json();
                const text = d.choices?.[0]?.message?.content?.toLowerCase().trim();
                const validTypes = ['simple', 'math', 'code', 'research', 'heavy'];

                for (const type of validTypes) {
                    if (text?.includes(type)) {
                        console.log(`[Analyzer] âœ… Question type: ${type}`);
                        return type;
                    }
                }
            }
        } catch (e) { continue; }
    }

    console.log('[Analyzer] âš ï¸ Default to simple');
    return 'simple';
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
//                    SMART MODEL SELECTOR
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

function selectModel(questionType) {
    const modelMap = {
        simple: MODELS.SIMPLE,
        math: MODELS.MATH,
        code: MODELS.CODE,
        research: MODELS.RESEARCH,
        heavy: MODELS.HEAVY,
    };
    return modelMap[questionType] || MODELS.SIMPLE;
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
//                    OPENROUTER - SPECIFIC MODEL
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async function callOpenRouterModel(model, systemPrompt, userPrompt, conversationHistory = [], maxTokens = 8000) {
    const keys = getOpenRouterKeys();
    if (keys.length === 0) return null;

    const messages = [{ role: 'system', content: systemPrompt }];

    if (conversationHistory && conversationHistory.length > 0) {
        for (const h of conversationHistory.slice(-10)) {
            if (h.prompt) messages.push({ role: 'user', content: h.prompt });
            if (h.results?.[0]?.result) messages.push({ role: 'assistant', content: h.results[0].result });
        }
    }

    messages.push({ role: 'user', content: userPrompt });

    // Try selected model with all keys
    for (let keyIndex = 0; keyIndex < keys.length; keyIndex++) {
        const key = keys[keyIndex];
        try {
            console.log(`[Worker] ğŸŸ£ Trying ${model.split('/')[1]?.split(':')[0]} (Key ${keyIndex + 1}/${keys.length})`);
            const res = await fetch('https://openrouter.ai/api/v1/chat/completions', {
                method: 'POST',
                headers: {
                    'Authorization': `Bearer ${key}`,
                    'Content-Type': 'application/json',
                    'HTTP-Referer': 'https://luks-pied.vercel.app',
                    'X-Title': 'Lukas AI'
                },
                body: JSON.stringify({ model, messages, max_tokens: maxTokens })
            });

            if (res.status === 429) {
                console.log(`[Worker] âš ï¸ Key ${keyIndex + 1} rate limited`);
                continue;
            }
            if (res.ok) {
                const d = await res.json();
                const text = d.choices?.[0]?.message?.content;
                if (text) {
                    console.log(`[Worker] âœ… Success: ${model.split('/')[1]?.split(':')[0]}`);
                    return text;
                }
            }
        } catch (e) { continue; }
    }

    // Fallback to other models
    console.log('[Worker] âš ï¸ Primary model failed, trying fallbacks...');
    for (const fallbackModel of FALLBACK_MODELS) {
        if (fallbackModel === model) continue; // Skip already tried

        for (const key of keys.slice(0, 2)) {
            try {
                console.log(`[Worker] ğŸ”„ Fallback: ${fallbackModel.split('/')[1]?.split(':')[0]}`);
                const res = await fetch('https://openrouter.ai/api/v1/chat/completions', {
                    method: 'POST',
                    headers: {
                        'Authorization': `Bearer ${key}`,
                        'Content-Type': 'application/json',
                        'HTTP-Referer': 'https://luks-pied.vercel.app',
                        'X-Title': 'Lukas AI'
                    },
                    body: JSON.stringify({ model: fallbackModel, messages, max_tokens: maxTokens })
                });

                if (res.ok) {
                    const d = await res.json();
                    const text = d.choices?.[0]?.message?.content;
                    if (text) {
                        console.log(`[Worker] âœ… Fallback success: ${fallbackModel.split('/')[1]?.split(':')[0]}`);
                        return text;
                    }
                }
            } catch (e) { continue; }
        }
    }

    return null;
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
//                    GROQ FALLBACK
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async function callGroq(systemPrompt, userPrompt, conversationHistory = [], maxTokens = 8000) {
    const keys = getGroqKeys();
    if (keys.length === 0) return null;

    const messages = [{ role: 'system', content: systemPrompt }];

    if (conversationHistory && conversationHistory.length > 0) {
        for (const h of conversationHistory.slice(-10)) {
            if (h.prompt) messages.push({ role: 'user', content: h.prompt });
            if (h.results?.[0]?.result) messages.push({ role: 'assistant', content: h.results[0].result });
        }
    }

    messages.push({ role: 'user', content: userPrompt });

    for (const model of GROQ_MODELS) {
        for (const key of keys) {
            try {
                console.log(`[Worker] ğŸŸ¢ Trying Groq: ${model}`);
                const res = await fetch('https://api.groq.com/openai/v1/chat/completions', {
                    method: 'POST',
                    headers: { 'Authorization': `Bearer ${key}`, 'Content-Type': 'application/json' },
                    body: JSON.stringify({ model, messages, max_tokens: maxTokens })
                });
                if (res.status === 429) continue;
                if (res.ok) {
                    const d = await res.json();
                    const text = d.choices?.[0]?.message?.content;
                    if (text) {
                        console.log(`[Worker] âœ… Groq success: ${model}`);
                        return text;
                    }
                }
            } catch (e) { continue; }
        }
    }
    return null;
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
//                    GEMINI REVIEWER
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async function geminiReviewer(response, question) {
    console.log('[Reviewer] ğŸ” Gemini reviewing...');

    const reviewPrompt = `Ø£Ù†Øª Ù…Ø±Ø§Ø¬Ø¹ Ù„ØºÙˆÙŠ. Ø±Ø§Ø¬Ø¹ Ù‡Ø°Ù‡ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¨Ø³Ø±Ø¹Ø©:

Ø§Ù„Ù…Ø·Ù„ÙˆØ¨:
1. Ø§Ø­Ø°Ù Ø£ÙŠ Ø­Ø±ÙˆÙ ØºÙŠØ± Ø¹Ø±Ø¨ÙŠØ© (ØµÙŠÙ†ÙŠØ©ØŒ Ø±ÙˆØ³ÙŠØ©ØŒ Ø¥Ù„Ø®)
2. ØµØ­Ø­ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
3. Ø§Ø³ØªØ¨Ø¯Ù„ Ø£ÙŠ Ø°ÙƒØ± Ù„Ø´Ø§ÙˆÙ…ÙŠ/Xiaomi Ø¨Ù€ "Ù„ÙˆÙƒØ§Ø³"

Ø§Ù„Ø³Ø¤Ø§Ù„: ${question.substring(0, 200)}

Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:
${response}

Ù‚Ø¯Ù… Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ù…Ø­Ø³Ù‘Ù†Ø© ÙÙ‚Ø·:`;

    const reviewed = await callGemini(reviewPrompt, 8000);
    if (reviewed) {
        console.log('[Reviewer] âœ… Review complete');
        return reviewed;
    }
    return response;
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
//                    MAIN HANDLER
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

export default async function handler(req, res) {
    res.setHeader('Access-Control-Allow-Origin', '*');
    res.setHeader('Access-Control-Allow-Methods', 'GET, POST, OPTIONS');
    res.setHeader('Access-Control-Allow-Headers', 'Content-Type');

    if (req.method === 'OPTIONS') return res.status(200).end();
    if (req.method !== 'POST') return res.status(405).json({ success: false, error: 'Method not allowed' });

    try {
        const { results, originalPrompt, prompt, conversationHistory } = req.body || {};
        const userPrompt = originalPrompt || prompt;
        if (!results || !userPrompt) return res.status(400).json({ success: false, error: 'Missing data' });

        const lang = /[\u0600-\u06FF]/.test(userPrompt) ? 'ar' : 'en';
        const resultsText = results.map((r, i) => `[${i + 1}] ${r.result || ''}`).join('\n\n');

        console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
        console.log(`[Synthesize] ğŸ§  New request`);
        console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');

        // Step 1: Analyze question with MiMo
        console.log('[Synthesize] ğŸ“Š Step 1: Analyzing question...');
        const questionType = await analyzeQuestion(userPrompt);

        // Step 2: Select best model
        const selectedModel = selectModel(questionType);
        console.log(`[Synthesize] ğŸ¯ Step 2: Selected model: ${selectedModel.split('/')[1]?.split(':')[0]} for type: ${questionType}`);

        // Step 3: Get response from selected model
        const userMessage = `${userPrompt}${resultsText ? `\n\nØ§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©:\n${resultsText}` : ''}`;

        console.log('[Synthesize] ğŸŸ£ Step 3: Getting response...');
        let response = await callOpenRouterModel(selectedModel, SYSTEM_PROMPT, userMessage, conversationHistory);

        // Step 4: Fallback to Groq
        if (!response) {
            console.log('[Synthesize] ğŸŸ¢ Step 4: OpenRouter failed, trying Groq...');
            response = await callGroq(SYSTEM_PROMPT, userMessage, conversationHistory);
        }

        // Step 5: Gemini review
        if (response) {
            console.log('[Synthesize] ğŸ”µ Step 5: Gemini reviewing...');
            response = await geminiReviewer(response, userPrompt);
        }

        if (!response) {
            response = lang === 'ar' ? 'Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø·Ù„Ø¨.' : 'Sorry, an error occurred.';
        }

        console.log(`[Synthesize] âœ… Done! (${response.length} chars)`);
        console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');

        res.status(200).json({
            success: true,
            data: response,
            meta: { questionType, model: selectedModel.split('/')[1]?.split(':')[0] }
        });
    } catch (error) {
        console.error('[Synthesize] âŒ Error:', error.message);
        res.status(500).json({ success: false, error: error.message });
    }
}
